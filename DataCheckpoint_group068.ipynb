{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8-final"
    },
    "colab": {
      "name": "DataCheckpoint_group068.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-611lQ2qBwg"
      },
      "source": [
        "# COGS 108 - Data Checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVSdElPMqBw6"
      },
      "source": [
        "# Names\n",
        "\n",
        "- Jared (Ruotian) Chen\n",
        "- Jimin Cheon\n",
        "- Kane Gu\n",
        "- Laurence D'Ercole\n",
        "- Nisha Davankar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoW5I0HSqBw7"
      },
      "source": [
        "<a id='research_question'></a>\n",
        "# Research Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb0_0MFJqBw7"
      },
      "source": [
        "## YouTube\n",
        "What attributes of a YouTube video affect its popularity/shareability (likes and/or shares)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZxN8oaVqBw8"
      },
      "source": [
        "# Dataset(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDKXNIfFqBw8"
      },
      "source": [
        "## Dataset Information\n",
        "\n",
        "- Dataset #1\n",
        "    - Dataset Name: YouTube's [official data API](https://developers.google.com/youtube/v3) (video listing)\n",
        "    - Link to the dataset: https://developers.google.com/youtube/v3/docs/videos/list\n",
        "    - Number of observations: approx. `200 * 30 == 6000`\n",
        "\n",
        "- Dataset #2\n",
        "    - Dataset Name: YouTube's [official data API](https://developers.google.com/youtube/v3) (video searching)\n",
        "    - Link to the dataset: https://developers.google.com/youtube/v3/docs/search/list\n",
        "    - Number of observations: approx. `4000 * 30 == 120000` (subject to change)\n",
        "\n",
        "- Dataset #3\n",
        "    - Dataset Name: YouTube's internal video metadata API (specifically `window.ytInitialPlayerResponse`)\n",
        "    - Link to the dataset: https://www.youtube.com/watch?v=[YOUTUBE_VIDEO_ID]\n",
        "    - Number of observations: depending on the number of existing observations\n",
        "\n",
        "\n",
        "Dataset #1 to #2 are used for retrieving information on likes/views/shares, genre, duration, date/time posted, content creator (i.e. subscription count), number of hashtags (from poster); Dataset #3 is specifically used for getting the number of ads in a video.\n",
        "\n",
        "Duplicates in the datasets can be removed by using the videos' unique IDs. Data cleaning and categorization happens in real time. Invalid or irrelevant entries, if any, will be immediately dropped. This design is intentional as we want the datasets to have as little footprint as possible (in memory and on disk). Data in memory may also be flushed to disk at any time, depending on the memory usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLsFJWPUqBw8"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "source": [
        "import types\n",
        "import pandas as pd\n",
        "df = None\n",
        "df_cache = 'EDA/dsamples/dcheckpoint_sample.pickle'\n",
        "\n",
        "from os import path\n",
        "if not path.exists(df_cache):\n",
        "    from EDA.dcollect import *\n",
        "\n",
        "    items = []\n",
        "    def item_each_fn(item):\n",
        "        global items\n",
        "        items.append(item)\n",
        "\n",
        "    count = 10\n",
        "    youtube_o = youtube(\n",
        "        modules = {'http': fasthttp()},\n",
        "        key = 'AIzaSyBKsF33Y1McGDdBWemcfcTbVyJu23XDNIk',\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36'\n",
        "        }\n",
        "    )\n",
        "    youtube_o.trending(\n",
        "        count = count,\n",
        "        parts = [\n",
        "            youtube.parts.ID,\n",
        "            youtube.parts.SNIPPET,\n",
        "            youtube.parts.STATS,\n",
        "            youtube.parts.details.CONTENT\n",
        "        ],\n",
        "        want = {\n",
        "           'id': None,\n",
        "            'creator': {\n",
        "                'id': None\n",
        "            },\n",
        "            'stats': {\n",
        "                'like': None,\n",
        "                'comment': None,\n",
        "                'view': None\n",
        "            },\n",
        "            'time': None,\n",
        "            'length': None\n",
        "        },\n",
        "        each_fn = item_each_fn\n",
        "    )\n",
        "\n",
        "    df = pd.json_normalize(items, sep = '.')\n",
        "    df.to_pickle(df_cache)\n",
        "else:\n",
        "    df = pd.read_pickle(df_cache)\n",
        "\n",
        "if not isinstance(df, type(None)):\n",
        "    print(df.head())\n",
        "    print(df.describe())\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "9fGdFLL3qBw8",
        "tags": []
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            id                      time          length  \\\n0  ssq6X6alZ3w 2021-02-12 05:00:14+00:00 0 days 00:04:04   \n1  zzd4ydafGR0 2021-02-12 05:03:49+00:00 0 days 00:03:22   \n2  aXzVF3XeS8M 2021-02-12 05:00:00+00:00 0 days 00:04:01   \n3  pyLJIEROIZo 2021-02-12 00:21:01+00:00 0 days 00:12:48   \n4  JSgrumHw-XA 2021-02-12 15:01:39+00:00 0 days 00:03:27   \n\n                 creator.id  stats.like  stats.comment  stats.view  \n0  UC0VOyT2OCBKdQhF3BAbZ-1g     1123835          64416     9839634  \n1  UCEB4a5o_6KfjxHwNMnmj54Q      438828          42788     3433960  \n2  UCANLZYMidaCbLQFWXBC95Jg      788872          72919     5553636  \n3  UCt_DaLB_NDqPVxezyvcfRtg      169945          19872     1686460  \n4  UCVIFCOJwv3emlVmBbPCZrvw      134165           4089      801628  \n                          length    stats.like  stats.comment    stats.view\ncount                         10  1.000000e+01      10.000000  1.000000e+01\nmean      0 days 00:04:42.200000  3.167475e+05   24145.500000  3.108622e+06\nstd    0 days 00:02:57.882483054  3.762017e+05   26780.546436  3.211529e+06\nmin              0 days 00:02:04  1.343800e+04    1916.000000  2.457600e+05\n25%       0 days 00:03:29.250000  3.963950e+04    4099.500000  5.586768e+05\n50%              0 days 00:03:56  1.520550e+05   12293.500000  2.070304e+06\n75%       0 days 00:04:23.500000  4.250640e+05   37781.000000  5.023717e+06\nmax              0 days 00:12:48  1.123835e+06   72919.000000  9.839634e+06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UdxEJ3CqBw9"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OHVwE-5qBw9"
      },
      "source": [
        "Describe your data cleaning steps here."
      ]
    },
    {
      "source": [
        "The Youtube API includes a variety of data sets about different aspects of the website. For our purposes, we will go through the API categories and focus on data sets like the Most Popular list, or a list of the video results associated with a specific search paramter. Because there is a lot of different functions and possible datasets to choose from, we will have to narrow our scope quite a bit. In addition the YouTube API displays the lists in JSON format, which we will need to convert to CSV in order to conduct our EDA.       See `EDA/{main,webapi,utils/decode}.py` for details."
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "V6ydWnw7qBw9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nug_B1HVqBw-"
      },
      "source": [
        "# Project Proposal (updated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_15kwwyHqBw-"
      },
      "source": [
        "| Meeting Date | Meeting Time    | Completed Before Meeting                | Discuss at Meeting                            |\n",
        "|--------------|-----------------|-----------------------------------------|-----------------------------------------------|\n",
        "| 2/2          | 6:00 PM         | Project Proposal done                   | Roles, data wrangling                         |\n",
        "| 2/10         | 5:00 PM         | Review feedback, Part of data wrangling | EDA ideas, Updated Proposal                   |\n",
        "| 2/11         | 7:00 PM         | Data wrangling and Partial EDA          | Discuss analysis and EDA                      |\n",
        "| 3/2          | 6:00 PM         | Outline of Analysis and EDA             | Continue Analysis                             |\n",
        "| 3/9          | 6:00 PM         | Finish Analysis                         | Ethics, Meeting with TA                       |\n",
        "| 3/16         | 6:00 PM         | Draft done                              | Final review                                  |\n",
        "| 3/19         | Before 11:59 PM | N/A                                     | Turn in Final Project & Group Project Surveys |"
      ]
    }
  ]
}